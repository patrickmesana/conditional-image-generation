C:\Anaconda2\envs\deeplearning\python.exe C:/Dev/conditional-image-generation/convolution.py
Using Theano backend.
Using cuDNN version 5110 on context None
Mapped name None to device cuda: GeForce GTX 1070 (0000:01:00.0)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 64, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 64, 64, 16)        448       
_________________________________________________________________
activation_1 (Activation)    (None, 64, 64, 16)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 32, 32, 32)        18464     
_________________________________________________________________
activation_5 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 64, 64, 16)        4624      
_________________________________________________________________
activation_6 (Activation)    (None, 64, 64, 16)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 64, 64, 3)         435       
=================================================================
Total params: 84,035
Trainable params: 84,035
Non-trainable params: 0
_________________________________________________________________
Train on 82611 samples, validate on 40438 samples
Epoch 1/100
82611/82611 [==============================] - 348s - loss: 0.5821 - acc: 0.0210 - val_loss: 0.5662 - val_acc: 0.0214
Epoch 2/100
82611/82611 [==============================] - 347s - loss: 0.5630 - acc: 0.0215 - val_loss: 0.5611 - val_acc: 0.0215
Epoch 3/100
82611/82611 [==============================] - 346s - loss: 0.5605 - acc: 0.0215 - val_loss: 0.5598 - val_acc: 0.0215
Epoch 4/100
82611/82611 [==============================] - 346s - loss: 0.5592 - acc: 0.0215 - val_loss: 0.5583 - val_acc: 0.0215
Epoch 5/100
82611/82611 [==============================] - 346s - loss: 0.5584 - acc: 0.0215 - val_loss: 0.5575 - val_acc: 0.0215
Epoch 6/100
82611/82611 [==============================] - 347s - loss: 0.5577 - acc: 0.0215 - val_loss: 0.5576 - val_acc: 0.0215
Epoch 7/100
82611/82611 [==============================] - 346s - loss: 0.5573 - acc: 0.0215 - val_loss: 0.5565 - val_acc: 0.0215
Epoch 8/100
82611/82611 [==============================] - 346s - loss: 0.5567 - acc: 0.0215 - val_loss: 0.5561 - val_acc: 0.0215
Epoch 9/100
82611/82611 [==============================] - 346s - loss: 0.5562 - acc: 0.0215 - val_loss: 0.5557 - val_acc: 0.0215
Epoch 10/100
82611/82611 [==============================] - 346s - loss: 0.5559 - acc: 0.0216 - val_loss: 0.5553 - val_acc: 0.0215
Epoch 11/100
82611/82611 [==============================] - 346s - loss: 0.5559 - acc: 0.0216 - val_loss: 0.5553 - val_acc: 0.0215
Epoch 12/100
82611/82611 [==============================] - 346s - loss: 0.5553 - acc: 0.0216 - val_loss: 0.5551 - val_acc: 0.0215
Epoch 13/100
82611/82611 [==============================] - 346s - loss: 0.5550 - acc: 0.0216 - val_loss: 0.5554 - val_acc: 0.0215
Epoch 14/100
82611/82611 [==============================] - 346s - loss: 0.5546 - acc: 0.0216 - val_loss: 0.5541 - val_acc: 0.0215
Epoch 15/100
82611/82611 [==============================] - 346s - loss: 0.5543 - acc: 0.0216 - val_loss: 0.5542 - val_acc: 0.0215
Epoch 16/100
82611/82611 [==============================] - 346s - loss: 0.5541 - acc: 0.0216 - val_loss: 0.5544 - val_acc: 0.0215
Epoch 17/100
82611/82611 [==============================] - 346s - loss: 0.5539 - acc: 0.0216 - val_loss: 0.5533 - val_acc: 0.0215
Epoch 18/100
82611/82611 [==============================] - 346s - loss: 0.5535 - acc: 0.0216 - val_loss: 0.5534 - val_acc: 0.0215
Epoch 19/100
82611/82611 [==============================] - 346s - loss: 0.5534 - acc: 0.0216 - val_loss: 0.5537 - val_acc: 0.0215
Epoch 20/100
82611/82611 [==============================] - 346s - loss: 0.5532 - acc: 0.0216 - val_loss: 0.5526 - val_acc: 0.0215
Epoch 21/100
82611/82611 [==============================] - 346s - loss: 0.5530 - acc: 0.0216 - val_loss: 0.5542 - val_acc: 0.0215
Epoch 22/100
82611/82611 [==============================] - 346s - loss: 0.5529 - acc: 0.0216 - val_loss: 0.5524 - val_acc: 0.0215
Epoch 23/100
82611/82611 [==============================] - 346s - loss: 0.5526 - acc: 0.0216 - val_loss: 0.5523 - val_acc: 0.0216
Epoch 24/100
82611/82611 [==============================] - 346s - loss: 0.5525 - acc: 0.0216 - val_loss: 0.5522 - val_acc: 0.0216
Epoch 25/100
82611/82611 [==============================] - 346s - loss: 0.5523 - acc: 0.0216 - val_loss: 0.5521 - val_acc: 0.0216
Epoch 26/100
82611/82611 [==============================] - 346s - loss: 0.5522 - acc: 0.0216 - val_loss: 0.5523 - val_acc: 0.0215
Epoch 27/100
82611/82611 [==============================] - 346s - loss: 0.5520 - acc: 0.0216 - val_loss: 0.5518 - val_acc: 0.0216
Epoch 28/100
82611/82611 [==============================] - 346s - loss: 0.5520 - acc: 0.0216 - val_loss: 0.5516 - val_acc: 0.0216
Epoch 29/100
82611/82611 [==============================] - 347s - loss: 0.5519 - acc: 0.0216 - val_loss: 0.5519 - val_acc: 0.0216
Epoch 30/100
82611/82611 [==============================] - 346s - loss: 0.5517 - acc: 0.0216 - val_loss: 0.5517 - val_acc: 0.0216
Epoch 31/100
82611/82611 [==============================] - 347s - loss: 0.5516 - acc: 0.0216 - val_loss: 0.5519 - val_acc: 0.0215
Epoch 32/100
82611/82611 [==============================] - 347s - loss: 0.5516 - acc: 0.0216 - val_loss: 0.5511 - val_acc: 0.0216
Epoch 33/100
82611/82611 [==============================] - 347s - loss: 0.5515 - acc: 0.0216 - val_loss: 0.5523 - val_acc: 0.0215
Epoch 34/100
82611/82611 [==============================] - 346s - loss: 0.5514 - acc: 0.0216 - val_loss: 0.5512 - val_acc: 0.0215
Epoch 35/100
82611/82611 [==============================] - 346s - loss: 0.5513 - acc: 0.0216 - val_loss: 0.5509 - val_acc: 0.0216
Epoch 36/100
82611/82611 [==============================] - 346s - loss: 0.5512 - acc: 0.0216 - val_loss: 0.5508 - val_acc: 0.0216
Epoch 37/100
82611/82611 [==============================] - 346s - loss: 0.5511 - acc: 0.0216 - val_loss: 0.5508 - val_acc: 0.0216
Epoch 38/100
82611/82611 [==============================] - 347s - loss: 0.5511 - acc: 0.0216 - val_loss: 0.5512 - val_acc: 0.0216
Epoch 39/100
82611/82611 [==============================] - 346s - loss: 0.5510 - acc: 0.0216 - val_loss: 0.5507 - val_acc: 0.0216
Epoch 40/100
82611/82611 [==============================] - 346s - loss: 0.5510 - acc: 0.0216 - val_loss: 0.5511 - val_acc: 0.0216
Epoch 41/100
82611/82611 [==============================] - 346s - loss: 0.5509 - acc: 0.0216 - val_loss: 0.5508 - val_acc: 0.0215
Epoch 42/100
82611/82611 [==============================] - 347s - loss: 0.5508 - acc: 0.0216 - val_loss: 0.5504 - val_acc: 0.0216
Epoch 43/100
82611/82611 [==============================] - 347s - loss: 0.5508 - acc: 0.0216 - val_loss: 0.5505 - val_acc: 0.0216
Epoch 44/100
82611/82611 [==============================] - 346s - loss: 0.5507 - acc: 0.0216 - val_loss: 0.5505 - val_acc: 0.0216
Epoch 45/100
82611/82611 [==============================] - 346s - loss: 0.5507 - acc: 0.0216 - val_loss: 0.5505 - val_acc: 0.0216
Epoch 46/100
82611/82611 [==============================] - 346s - loss: 0.5506 - acc: 0.0216 - val_loss: 0.5504 - val_acc: 0.0216
Epoch 47/100
82611/82611 [==============================] - 346s - loss: 0.5506 - acc: 0.0216 - val_loss: 0.5504 - val_acc: 0.0216
Epoch 48/100
82611/82611 [==============================] - 347s - loss: 0.5505 - acc: 0.0216 - val_loss: 0.5501 - val_acc: 0.0216
Epoch 49/100
82611/82611 [==============================] - 347s - loss: 0.5505 - acc: 0.0216 - val_loss: 0.5501 - val_acc: 0.0216
Epoch 50/100
82611/82611 [==============================] - 347s - loss: 0.5504 - acc: 0.0216 - val_loss: 0.5501 - val_acc: 0.0216
Epoch 51/100
82611/82611 [==============================] - 347s - loss: 0.5504 - acc: 0.0216 - val_loss: 0.5510 - val_acc: 0.0215
Epoch 52/100
82611/82611 [==============================] - 347s - loss: 0.5503 - acc: 0.0216 - val_loss: 0.5502 - val_acc: 0.0216
Epoch 53/100
82611/82611 [==============================] - 346s - loss: 0.5502 - acc: 0.0216 - val_loss: 0.5502 - val_acc: 0.0215
Epoch 54/100
82611/82611 [==============================] - 346s - loss: 0.5502 - acc: 0.0216 - val_loss: 0.5501 - val_acc: 0.0216
Epoch 55/100
82611/82611 [==============================] - 346s - loss: 0.5502 - acc: 0.0216 - val_loss: 0.5503 - val_acc: 0.0216
Epoch 56/100
82611/82611 [==============================] - 346s - loss: 0.5501 - acc: 0.0216 - val_loss: 0.5500 - val_acc: 0.0216
Epoch 57/100
82611/82611 [==============================] - 346s - loss: 0.5501 - acc: 0.0216 - val_loss: 0.5498 - val_acc: 0.0216
Epoch 58/100
82611/82611 [==============================] - 347s - loss: 0.5501 - acc: 0.0216 - val_loss: 0.5498 - val_acc: 0.0216
Epoch 59/100
82611/82611 [==============================] - 347s - loss: 0.5500 - acc: 0.0216 - val_loss: 0.5507 - val_acc: 0.0216
Epoch 60/100
82611/82611 [==============================] - 346s - loss: 0.5500 - acc: 0.0216 - val_loss: 0.5497 - val_acc: 0.0216
Epoch 61/100
82611/82611 [==============================] - 347s - loss: 0.5500 - acc: 0.0216 - val_loss: 0.5498 - val_acc: 0.0216
Epoch 62/100
82611/82611 [==============================] - 346s - loss: 0.5499 - acc: 0.0216 - val_loss: 0.5497 - val_acc: 0.0216
Epoch 63/100
82611/82611 [==============================] - 346s - loss: 0.5499 - acc: 0.0216 - val_loss: 0.5498 - val_acc: 0.0216
Epoch 64/100
82611/82611 [==============================] - 346s - loss: 0.5499 - acc: 0.0216 - val_loss: 0.5510 - val_acc: 0.0216
Epoch 65/100
82611/82611 [==============================] - 346s - loss: 0.5498 - acc: 0.0216 - val_loss: 0.5497 - val_acc: 0.0216
Epoch 66/100
82611/82611 [==============================] - 346s - loss: 0.5498 - acc: 0.0216 - val_loss: 0.5495 - val_acc: 0.0216
Epoch 67/100
82611/82611 [==============================] - 346s - loss: 0.5498 - acc: 0.0216 - val_loss: 0.5494 - val_acc: 0.0216
Epoch 68/100
82611/82611 [==============================] - 346s - loss: 0.5497 - acc: 0.0216 - val_loss: 0.5496 - val_acc: 0.0216
Epoch 69/100
82611/82611 [==============================] - 346s - loss: 0.5497 - acc: 0.0216 - val_loss: 0.5500 - val_acc: 0.0216
Epoch 70/100
82611/82611 [==============================] - 347s - loss: 0.5497 - acc: 0.0216 - val_loss: 0.5494 - val_acc: 0.0216
Epoch 71/100
82611/82611 [==============================] - 346s - loss: 0.5497 - acc: 0.0216 - val_loss: 0.5496 - val_acc: 0.0216
Epoch 72/100
82611/82611 [==============================] - 347s - loss: 0.5497 - acc: 0.0216 - val_loss: 0.5494 - val_acc: 0.0216
Epoch 73/100
82611/82611 [==============================] - 347s - loss: 0.5496 - acc: 0.0216 - val_loss: 0.5497 - val_acc: 0.0216
Epoch 74/100
82611/82611 [==============================] - 347s - loss: 0.5496 - acc: 0.0216 - val_loss: 0.5495 - val_acc: 0.0216
Epoch 75/100
82611/82611 [==============================] - 346s - loss: 0.5495 - acc: 0.0216 - val_loss: 0.5495 - val_acc: 0.0216
Epoch 76/100
82611/82611 [==============================] - 346s - loss: 0.5495 - acc: 0.0216 - val_loss: 0.5493 - val_acc: 0.0216
Epoch 77/100
82611/82611 [==============================] - 346s - loss: 0.5495 - acc: 0.0216 - val_loss: 0.5496 - val_acc: 0.0216
Epoch 78/100
82611/82611 [==============================] - 346s - loss: 0.5494 - acc: 0.0216 - val_loss: 0.5495 - val_acc: 0.0216
Epoch 79/100
82611/82611 [==============================] - 346s - loss: 0.5495 - acc: 0.0216 - val_loss: 0.5493 - val_acc: 0.0216
Epoch 80/100
82611/82611 [==============================] - 346s - loss: 0.5495 - acc: 0.0216 - val_loss: 0.5492 - val_acc: 0.0216
Epoch 81/100
82611/82611 [==============================] - 346s - loss: 0.5494 - acc: 0.0216 - val_loss: 0.5492 - val_acc: 0.0216
Epoch 82/100
82611/82611 [==============================] - 347s - loss: 0.5494 - acc: 0.0216 - val_loss: 0.5494 - val_acc: 0.0216
Epoch 83/100
82611/82611 [==============================] - 346s - loss: 0.5494 - acc: 0.0216 - val_loss: 0.5492 - val_acc: 0.0216
Epoch 84/100
82611/82611 [==============================] - 346s - loss: 0.5494 - acc: 0.0216 - val_loss: 0.5491 - val_acc: 0.0216
Epoch 85/100
82611/82611 [==============================] - 346s - loss: 0.5493 - acc: 0.0216 - val_loss: 0.5492 - val_acc: 0.0216
Epoch 86/100
82611/82611 [==============================] - 346s - loss: 0.5493 - acc: 0.0216 - val_loss: 0.5492 - val_acc: 0.0216
Epoch 87/100
82611/82611 [==============================] - 347s - loss: 0.5493 - acc: 0.0216 - val_loss: 0.5494 - val_acc: 0.0216
Epoch 88/100
82611/82611 [==============================] - 347s - loss: 0.5493 - acc: 0.0216 - val_loss: 0.5494 - val_acc: 0.0216
Epoch 89/100
82611/82611 [==============================] - 347s - loss: 0.5493 - acc: 0.0216 - val_loss: 0.5491 - val_acc: 0.0216
Epoch 90/100
82611/82611 [==============================] - 347s - loss: 0.5492 - acc: 0.0216 - val_loss: 0.5491 - val_acc: 0.0216
Epoch 91/100
82611/82611 [==============================] - 347s - loss: 0.5492 - acc: 0.0216 - val_loss: 0.5498 - val_acc: 0.0216
Epoch 92/100
82611/82611 [==============================] - 347s - loss: 0.5492 - acc: 0.0216 - val_loss: 0.5491 - val_acc: 0.0216
Epoch 93/100
82611/82611 [==============================] - 346s - loss: 0.5492 - acc: 0.0216 - val_loss: 0.5490 - val_acc: 0.0216
Epoch 94/100
82611/82611 [==============================] - 346s - loss: 0.5492 - acc: 0.0216 - val_loss: 0.5496 - val_acc: 0.0216
Epoch 95/100
82611/82611 [==============================] - 346s - loss: 0.5492 - acc: 0.0216 - val_loss: 0.5494 - val_acc: 0.0216
Epoch 96/100
82611/82611 [==============================] - 347s - loss: 0.5492 - acc: 0.0216 - val_loss: 0.5493 - val_acc: 0.0216
Epoch 97/100
82611/82611 [==============================] - 346s - loss: 0.5491 - acc: 0.0216 - val_loss: 0.5490 - val_acc: 0.0216
Epoch 98/100
82611/82611 [==============================] - 346s - loss: 0.5491 - acc: 0.0216 - val_loss: 0.5490 - val_acc: 0.0216
Epoch 99/100
82611/82611 [==============================] - 346s - loss: 0.5491 - acc: 0.0216 - val_loss: 0.5492 - val_acc: 0.0216
Epoch 100/100
82611/82611 [==============================] - 348s - loss: 0.5491 - acc: 0.0216 - val_loss: 0.5489 - val_acc: 0.0216
['acc', 'loss', 'val_acc', 'val_loss']

Process finished with exit code 0
