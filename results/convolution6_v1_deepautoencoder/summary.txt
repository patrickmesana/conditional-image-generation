C:\Anaconda2\envs\deeplearning\python.exe C:/Dev/conditional-image-generation/convolution.py
Using Theano backend.
Using cuDNN version 5110 on context None
Mapped name None to device cuda: GeForce GTX 1070 (0000:01:00.0)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 64, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 64, 64, 16)        448       
_________________________________________________________________
activation_1 (Activation)    (None, 64, 64, 16)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 32, 32, 32)        18464     
_________________________________________________________________
activation_5 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 64, 64, 16)        4624      
_________________________________________________________________
activation_6 (Activation)    (None, 64, 64, 16)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 64, 64, 3)         435       
=================================================================
Total params: 84,035
Trainable params: 84,035
Non-trainable params: 0
_________________________________________________________________
Train on 82611 samples, validate on 40438 samples
Epoch 1/30
82611/82611 [==============================] - 348s - loss: 0.5825 - acc: 0.0210 - val_loss: 0.5671 - val_acc: 0.0214
Epoch 2/30
82611/82611 [==============================] - 346s - loss: 0.5631 - acc: 0.0215 - val_loss: 0.5620 - val_acc: 0.0214
Epoch 3/30
82611/82611 [==============================] - 346s - loss: 0.5606 - acc: 0.0215 - val_loss: 0.5598 - val_acc: 0.0215
Epoch 4/30
82611/82611 [==============================] - 346s - loss: 0.5595 - acc: 0.0215 - val_loss: 0.5588 - val_acc: 0.0215
Epoch 5/30
82611/82611 [==============================] - 347s - loss: 0.5584 - acc: 0.0215 - val_loss: 0.5578 - val_acc: 0.0215
Epoch 6/30
82611/82611 [==============================] - 346s - loss: 0.5579 - acc: 0.0215 - val_loss: 0.5571 - val_acc: 0.0215
Epoch 7/30
82611/82611 [==============================] - 346s - loss: 0.5573 - acc: 0.0215 - val_loss: 0.5567 - val_acc: 0.0215
Epoch 8/30
82611/82611 [==============================] - 346s - loss: 0.5567 - acc: 0.0215 - val_loss: 0.5563 - val_acc: 0.0215
Epoch 9/30
82611/82611 [==============================] - 346s - loss: 0.5564 - acc: 0.0215 - val_loss: 0.5561 - val_acc: 0.0215
Epoch 10/30
82611/82611 [==============================] - 347s - loss: 0.5560 - acc: 0.0215 - val_loss: 0.5554 - val_acc: 0.0215
Epoch 11/30
82611/82611 [==============================] - 347s - loss: 0.5557 - acc: 0.0216 - val_loss: 0.5553 - val_acc: 0.0215
Epoch 12/30
82611/82611 [==============================] - 347s - loss: 0.5553 - acc: 0.0216 - val_loss: 0.5553 - val_acc: 0.0215
Epoch 13/30
82611/82611 [==============================] - 346s - loss: 0.5551 - acc: 0.0216 - val_loss: 0.5558 - val_acc: 0.0215
Epoch 14/30
82611/82611 [==============================] - 346s - loss: 0.5548 - acc: 0.0216 - val_loss: 0.5542 - val_acc: 0.0215
Epoch 15/30
82611/82611 [==============================] - 346s - loss: 0.5546 - acc: 0.0216 - val_loss: 0.5542 - val_acc: 0.0215
Epoch 16/30
82611/82611 [==============================] - 346s - loss: 0.5542 - acc: 0.0216 - val_loss: 0.5537 - val_acc: 0.0215
Epoch 17/30
82611/82611 [==============================] - 347s - loss: 0.5541 - acc: 0.0216 - val_loss: 0.5552 - val_acc: 0.0215
Epoch 18/30
82611/82611 [==============================] - 346s - loss: 0.5538 - acc: 0.0216 - val_loss: 0.5534 - val_acc: 0.0215
Epoch 19/30
82611/82611 [==============================] - 346s - loss: 0.5535 - acc: 0.0216 - val_loss: 0.5529 - val_acc: 0.0215
Epoch 20/30
82611/82611 [==============================] - 346s - loss: 0.5532 - acc: 0.0216 - val_loss: 0.5528 - val_acc: 0.0215
Epoch 21/30
82611/82611 [==============================] - 346s - loss: 0.5530 - acc: 0.0216 - val_loss: 0.5528 - val_acc: 0.0215
Epoch 22/30
82611/82611 [==============================] - 346s - loss: 0.5528 - acc: 0.0216 - val_loss: 0.5523 - val_acc: 0.0215
Epoch 23/30
82611/82611 [==============================] - 346s - loss: 0.5526 - acc: 0.0216 - val_loss: 0.5523 - val_acc: 0.0215
Epoch 24/30
82611/82611 [==============================] - 346s - loss: 0.5525 - acc: 0.0216 - val_loss: 0.5521 - val_acc: 0.0215
Epoch 25/30
82611/82611 [==============================] - 346s - loss: 0.5523 - acc: 0.0216 - val_loss: 0.5519 - val_acc: 0.0215
Epoch 26/30
82611/82611 [==============================] - 346s - loss: 0.5522 - acc: 0.0216 - val_loss: 0.5519 - val_acc: 0.0216
Epoch 27/30
82611/82611 [==============================] - 347s - loss: 0.5520 - acc: 0.0216 - val_loss: 0.5516 - val_acc: 0.0215
Epoch 28/30
82611/82611 [==============================] - 347s - loss: 0.5519 - acc: 0.0216 - val_loss: 0.5515 - val_acc: 0.0216
Epoch 29/30
82611/82611 [==============================] - 347s - loss: 0.5518 - acc: 0.0216 - val_loss: 0.5514 - val_acc: 0.0216
Epoch 30/30
82611/82611 [==============================] - 346s - loss: 0.5517 - acc: 0.0216 - val_loss: 0.5513 - val_acc: 0.0216
['acc', 'loss', 'val_acc', 'val_loss']

Process finished with exit code 0