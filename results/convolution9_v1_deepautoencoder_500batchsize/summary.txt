C:\Anaconda2\envs\deeplearning\python.exe C:/Dev/conditional-image-generation/convolution.py
Using Theano backend.
Using cuDNN version 5110 on context None
Mapped name None to device cuda: GeForce GTX 1070 (0000:01:00.0)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 64, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 64, 64, 16)        448       
_________________________________________________________________
activation_1 (Activation)    (None, 64, 64, 16)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 64)        0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 32, 32, 32)        18464     
_________________________________________________________________
activation_5 (Activation)    (None, 32, 32, 32)        0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 64, 64, 16)        4624      
_________________________________________________________________
activation_6 (Activation)    (None, 64, 64, 16)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 64, 64, 3)         435       
=================================================================
Total params: 84,035
Trainable params: 84,035
Non-trainable params: 0
_________________________________________________________________
Train on 82611 samples, validate on 40438 samples
Epoch 1/100
82611/82611 [==============================] - 350s - loss: 0.5968 - acc: 0.0205 - val_loss: 0.5739 - val_acc: 0.0213
Epoch 2/100
82611/82611 [==============================] - 349s - loss: 0.5688 - acc: 0.0214 - val_loss: 0.5666 - val_acc: 0.0214
Epoch 3/100
82611/82611 [==============================] - 348s - loss: 0.5643 - acc: 0.0214 - val_loss: 0.5626 - val_acc: 0.0214
Epoch 4/100
82611/82611 [==============================] - 351s - loss: 0.5623 - acc: 0.0215 - val_loss: 0.5620 - val_acc: 0.0215
Epoch 5/100
82611/82611 [==============================] - 352s - loss: 0.5611 - acc: 0.0215 - val_loss: 0.5607 - val_acc: 0.0215
Epoch 6/100
82611/82611 [==============================] - 349s - loss: 0.5601 - acc: 0.0215 - val_loss: 0.5598 - val_acc: 0.0215
Epoch 7/100
82611/82611 [==============================] - 348s - loss: 0.5595 - acc: 0.0215 - val_loss: 0.5587 - val_acc: 0.0215
Epoch 8/100
82611/82611 [==============================] - 348s - loss: 0.5590 - acc: 0.0215 - val_loss: 0.5591 - val_acc: 0.0215
Epoch 9/100
82611/82611 [==============================] - 349s - loss: 0.5583 - acc: 0.0215 - val_loss: 0.5600 - val_acc: 0.0215
Epoch 10/100
82611/82611 [==============================] - 349s - loss: 0.5581 - acc: 0.0215 - val_loss: 0.5575 - val_acc: 0.0215
Epoch 11/100
82611/82611 [==============================] - 348s - loss: 0.5577 - acc: 0.0215 - val_loss: 0.5581 - val_acc: 0.0215
Epoch 12/100
82611/82611 [==============================] - 350s - loss: 0.5575 - acc: 0.0215 - val_loss: 0.5568 - val_acc: 0.0215
Epoch 13/100
82611/82611 [==============================] - 349s - loss: 0.5570 - acc: 0.0215 - val_loss: 0.5577 - val_acc: 0.0215
Epoch 14/100
82611/82611 [==============================] - 347s - loss: 0.5568 - acc: 0.0215 - val_loss: 0.5568 - val_acc: 0.0215
Epoch 15/100
82611/82611 [==============================] - 346s - loss: 0.5567 - acc: 0.0215 - val_loss: 0.5560 - val_acc: 0.0215
Epoch 16/100
82611/82611 [==============================] - 347s - loss: 0.5566 - acc: 0.0215 - val_loss: 0.5561 - val_acc: 0.0215
Epoch 17/100
82611/82611 [==============================] - 349s - loss: 0.5565 - acc: 0.0215 - val_loss: 0.5563 - val_acc: 0.0215
Epoch 18/100
82611/82611 [==============================] - 346s - loss: 0.5560 - acc: 0.0215 - val_loss: 0.5558 - val_acc: 0.0215
Epoch 19/100
82611/82611 [==============================] - 346s - loss: 0.5561 - acc: 0.0215 - val_loss: 0.5554 - val_acc: 0.0215
Epoch 20/100
82611/82611 [==============================] - 346s - loss: 0.5557 - acc: 0.0215 - val_loss: 0.5552 - val_acc: 0.0215
Epoch 21/100
82611/82611 [==============================] - 347s - loss: 0.5558 - acc: 0.0215 - val_loss: 0.5560 - val_acc: 0.0215
Epoch 22/100
82611/82611 [==============================] - 351s - loss: 0.5554 - acc: 0.0216 - val_loss: 0.5560 - val_acc: 0.0215
Epoch 23/100
82611/82611 [==============================] - 347s - loss: 0.5553 - acc: 0.0216 - val_loss: 0.5553 - val_acc: 0.0215
Epoch 24/100
82611/82611 [==============================] - 350s - loss: 0.5552 - acc: 0.0216 - val_loss: 0.5547 - val_acc: 0.0215
Epoch 25/100
82611/82611 [==============================] - 347s - loss: 0.5550 - acc: 0.0216 - val_loss: 0.5553 - val_acc: 0.0215
Epoch 26/100
82611/82611 [==============================] - 348s - loss: 0.5548 - acc: 0.0216 - val_loss: 0.5553 - val_acc: 0.0215
Epoch 27/100
82611/82611 [==============================] - 351s - loss: 0.5547 - acc: 0.0216 - val_loss: 0.5548 - val_acc: 0.0215
Epoch 28/100
82611/82611 [==============================] - 346s - loss: 0.5547 - acc: 0.0216 - val_loss: 0.5540 - val_acc: 0.0215
Epoch 29/100
82611/82611 [==============================] - 348s - loss: 0.5544 - acc: 0.0216 - val_loss: 0.5544 - val_acc: 0.0215
Epoch 30/100
82611/82611 [==============================] - 350s - loss: 0.5543 - acc: 0.0216 - val_loss: 0.5539 - val_acc: 0.0215
Epoch 31/100
82611/82611 [==============================] - 348s - loss: 0.5542 - acc: 0.0216 - val_loss: 0.5536 - val_acc: 0.0215
Epoch 32/100
82611/82611 [==============================] - 349s - loss: 0.5540 - acc: 0.0216 - val_loss: 0.5537 - val_acc: 0.0215
Epoch 33/100
82611/82611 [==============================] - 350s - loss: 0.5539 - acc: 0.0216 - val_loss: 0.5537 - val_acc: 0.0215
Epoch 34/100
82611/82611 [==============================] - 347s - loss: 0.5538 - acc: 0.0216 - val_loss: 0.5534 - val_acc: 0.0215
Epoch 35/100
82611/82611 [==============================] - 347s - loss: 0.5538 - acc: 0.0216 - val_loss: 0.5534 - val_acc: 0.0215
Epoch 36/100
82611/82611 [==============================] - 348s - loss: 0.5535 - acc: 0.0216 - val_loss: 0.5530 - val_acc: 0.0215
Epoch 37/100
82611/82611 [==============================] - 348s - loss: 0.5535 - acc: 0.0216 - val_loss: 0.5532 - val_acc: 0.0215
Epoch 38/100
82611/82611 [==============================] - 349s - loss: 0.5533 - acc: 0.0216 - val_loss: 0.5534 - val_acc: 0.0215
Epoch 39/100
82611/82611 [==============================] - 346s - loss: 0.5533 - acc: 0.0216 - val_loss: 0.5533 - val_acc: 0.0215
Epoch 40/100
82611/82611 [==============================] - 346s - loss: 0.5531 - acc: 0.0216 - val_loss: 0.5528 - val_acc: 0.0215
Epoch 41/100
82611/82611 [==============================] - 346s - loss: 0.5531 - acc: 0.0216 - val_loss: 0.5528 - val_acc: 0.0215
Epoch 42/100
82611/82611 [==============================] - 348s - loss: 0.5529 - acc: 0.0216 - val_loss: 0.5525 - val_acc: 0.0215
Epoch 43/100
82611/82611 [==============================] - 346s - loss: 0.5530 - acc: 0.0216 - val_loss: 0.5524 - val_acc: 0.0215
Epoch 44/100
82611/82611 [==============================] - 347s - loss: 0.5527 - acc: 0.0216 - val_loss: 0.5530 - val_acc: 0.0215
Epoch 45/100
82611/82611 [==============================] - 349s - loss: 0.5527 - acc: 0.0216 - val_loss: 0.5525 - val_acc: 0.0215
Epoch 46/100
82611/82611 [==============================] - 348s - loss: 0.5527 - acc: 0.0216 - val_loss: 0.5522 - val_acc: 0.0215
Epoch 47/100
82611/82611 [==============================] - 347s - loss: 0.5526 - acc: 0.0216 - val_loss: 0.5523 - val_acc: 0.0215
Epoch 48/100
82611/82611 [==============================] - 349s - loss: 0.5524 - acc: 0.0216 - val_loss: 0.5521 - val_acc: 0.0215
Epoch 49/100
82611/82611 [==============================] - 347s - loss: 0.5524 - acc: 0.0216 - val_loss: 0.5524 - val_acc: 0.0215
Epoch 50/100
82611/82611 [==============================] - 348s - loss: 0.5523 - acc: 0.0216 - val_loss: 0.5540 - val_acc: 0.0215
Epoch 51/100
82611/82611 [==============================] - 348s - loss: 0.5523 - acc: 0.0216 - val_loss: 0.5519 - val_acc: 0.0215
Epoch 52/100
82611/82611 [==============================] - 348s - loss: 0.5522 - acc: 0.0216 - val_loss: 0.5520 - val_acc: 0.0216
Epoch 53/100
82611/82611 [==============================] - 349s - loss: 0.5521 - acc: 0.0216 - val_loss: 0.5525 - val_acc: 0.0215
Epoch 54/100
82611/82611 [==============================] - 347s - loss: 0.5522 - acc: 0.0216 - val_loss: 0.5518 - val_acc: 0.0215
Epoch 55/100
82611/82611 [==============================] - 348s - loss: 0.5519 - acc: 0.0216 - val_loss: 0.5521 - val_acc: 0.0215
Epoch 56/100
82611/82611 [==============================] - 346s - loss: 0.5519 - acc: 0.0216 - val_loss: 0.5515 - val_acc: 0.0215
Epoch 57/100
82611/82611 [==============================] - 348s - loss: 0.5518 - acc: 0.0216 - val_loss: 0.5514 - val_acc: 0.0216
Epoch 58/100
82611/82611 [==============================] - 349s - loss: 0.5518 - acc: 0.0216 - val_loss: 0.5516 - val_acc: 0.0215
Epoch 59/100
82611/82611 [==============================] - 349s - loss: 0.5517 - acc: 0.0216 - val_loss: 0.5530 - val_acc: 0.0215
Epoch 60/100
82611/82611 [==============================] - 349s - loss: 0.5518 - acc: 0.0216 - val_loss: 0.5519 - val_acc: 0.0215
Epoch 61/100
82611/82611 [==============================] - 347s - loss: 0.5515 - acc: 0.0216 - val_loss: 0.5526 - val_acc: 0.0215
['acc', 'loss', 'val_acc', 'val_loss']

Process finished with exit code 0