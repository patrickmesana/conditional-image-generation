C:\Anaconda2\envs\deeplearning\python.exe C:/Dev/conditional-image-generation/convolution.py
Using Theano backend.
Using cuDNN version 5110 on context None
Mapped name None to device cuda: GeForce GTX 1070 (0000:01:00.0)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 64, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       
_________________________________________________________________
batch_normalization_1 (Batch (None, 64, 64, 32)        128       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 16)        4624      
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 16)        64        
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 16)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 16)        2320      
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 16)        64        
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 16)        0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
batch_normalization_4 (Batch (None, 32, 32, 32)        128       
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 32)        0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 64, 64, 3)         867       
=================================================================
Total params: 13,731
Trainable params: 13,539
Non-trainable params: 192
_________________________________________________________________
Train on 82611 samples, validate on 40438 samples
Epoch 1/30
82611/82611 [==============================] - 1511s - loss: 0.5852 - acc: 0.0209 - val_loss: 0.6288 - val_acc: 0.0205
Epoch 2/30
82611/82611 [==============================] - 1511s - loss: 0.5680 - acc: 0.0213 - val_loss: 0.5698 - val_acc: 0.0211
Epoch 3/30
82611/82611 [==============================] - 1511s - loss: 0.5649 - acc: 0.0214 - val_loss: 0.5681 - val_acc: 0.0208
Epoch 4/30
82611/82611 [==============================] - 1511s - loss: 0.5634 - acc: 0.0214 - val_loss: 0.5631 - val_acc: 0.0214
Epoch 5/30
82611/82611 [==============================] - 1511s - loss: 0.5622 - acc: 0.0214 - val_loss: 0.5617 - val_acc: 0.0214
Epoch 6/30
82611/82611 [==============================] - 1511s - loss: 0.5614 - acc: 0.0214 - val_loss: 0.5624 - val_acc: 0.0214
Epoch 7/30
82611/82611 [==============================] - 1510s - loss: 0.5607 - acc: 0.0214 - val_loss: 0.5621 - val_acc: 0.0214
Epoch 8/30
82611/82611 [==============================] - 1510s - loss: 0.5603 - acc: 0.0214 - val_loss: 0.5607 - val_acc: 0.0214
Epoch 9/30
82611/82611 [==============================] - 1510s - loss: 0.5598 - acc: 0.0214 - val_loss: 0.5607 - val_acc: 0.0214
Epoch 10/30
82611/82611 [==============================] - 1510s - loss: 0.5594 - acc: 0.0214 - val_loss: 0.5683 - val_acc: 0.0213
Epoch 11/30
82611/82611 [==============================] - 1510s - loss: 0.5591 - acc: 0.0214 - val_loss: 0.5594 - val_acc: 0.0214
Epoch 12/30
82611/82611 [==============================] - 1510s - loss: 0.5588 - acc: 0.0215 - val_loss: 0.5597 - val_acc: 0.0214
Epoch 13/30
82611/82611 [==============================] - 1510s - loss: 0.5585 - acc: 0.0215 - val_loss: 0.5591 - val_acc: 0.0214
Epoch 14/30
82611/82611 [==============================] - 1510s - loss: 0.5583 - acc: 0.0215 - val_loss: 0.5584 - val_acc: 0.0214
Epoch 15/30
82611/82611 [==============================] - 1637s - loss: 0.5580 - acc: 0.0215 - val_loss: 0.5584 - val_acc: 0.0214
Epoch 16/30
82611/82611 [==============================] - 1677s - loss: 0.5578 - acc: 0.0215 - val_loss: 0.5680 - val_acc: 0.0213
Epoch 17/30
82611/82611 [==============================] - 1677s - loss: 0.5577 - acc: 0.0215 - val_loss: 0.5652 - val_acc: 0.0213
Epoch 18/30
82611/82611 [==============================] - 1677s - loss: 0.5574 - acc: 0.0215 - val_loss: 0.5589 - val_acc: 0.0214
['acc', 'loss', 'val_acc', 'val_loss']

Process finished with exit code 0